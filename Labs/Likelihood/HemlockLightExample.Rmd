<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { 
      equationNumbers: {
 
            autoNumber: "all",
            formatNumber: function (n) {return +n}
      } 
  }
});
</script>


<style>

/* uncomment out this to generate exercise */
#.hider {display: none;} 
#.hider2 {display: inline;} 

/* uncomment out this to generate key */
.hider {display: inline;} 
.hider2 {display: none;} 

</style>
---
output: html_document
---
<img src="../Logo.png" style="position:absolute;top:10px;right:125px;width:250px;height=250px" />

### `r fileName="../Title.txt";readChar(fileName,file.info(fileName)$size)`
#### Estimating Model Parameters Using Maximum Likelihood 
#### `r format(Sys.Date(), format="%B %d, %Y")`

- - -
#### Table of Contents

[I. General approach][]

[II. Problem][]

[III. Getting started][]

[IV. Setting up the spreadsheet][]

[V. Using Solver][]

[VI. Using R to do the same thing][]

[VII. Incorporating prior information in an MLE][]

[VIII. References][]

```{r preliminaries, include = FALSE}
rm(list = ls())
library(knitr)

knitr::opts_chunk$set(cache = FALSE, warnings = FALSE, tidy = FALSE)

set.seed(5)
```

<br>

#### I. General approach

To get the most out of this lab, you must think of the specific problems you confront here as examples from an infinite variety of analytical challenges that can be attacked using the same general approach:

* Think about how the data arise.
* Develop a mathematical model of the process that produces the data.
* Choose the appropriate likelihood function to tie the predictions of your process model to the data. 
* Use maximum likelihood (in this exercise) or Bayesian methods (later) to learn about the parameters in your process model and associated uncertainties.
* In this exercise we will not attempt to distinguish among different sources of uncertainty, i.e., process variance, observation error, and random effects.  These distinctions will be made soon enough, after we have developed a bit more statistical sophistication.  Moreover, we are leaving the problem of model selection until later in the course.

<br>

#### II. Problem

Coates and Burton (1999) studied the influence of light availability on growth increment of saplings of species of conifers in northwestern interior cedar-hemlock forests of British Columbia.  They used the deterministic model, 

$$\mu_{i}=\cfrac{\alpha\big(L_{i}-c\big)}{\cfrac{\alpha}{\gamma} + \big(L_{i}-c\big)},$$

where:

$\mu_{i}$ = prediction of growth increment of the $i_{th}$ hemlock tree (cm/year)

$\alpha$ = maximum growth rate (cm/year)

$\gamma$ = slope of curve at low light (cm/year)

$c$ = light index where growth = 0 (unitless)

$L_{i}$ = measured index of light availability for the $i_{th}$ hemlock tree, i.e. the proportion of the hemisphere above canopy open to light $\times$ 100 (unitless).

We will return to this model several times during the course.

Assume that growth increment can be any real number.  It can negative because moose can eat the tops of saplings.  Write a model for the data.

<div class="hider">
$$\mu_{i}=\cfrac{\alpha\big(L_{i}-c\big)}{\cfrac{\alpha}{\gamma} + \big(L_{i}-c\big)}$$
$$y_i \sim \text{normal}(\mu_i,\sigma)$$

</div>



<br>

#### III. Getting started

Obtain maximum likelihood estimates (MLE’s) of the model parameters using Solver in Excel. Ok, ok, you have invested buckets of time and effort learning R and now I am asking you to work in Excel?  What am I thinking?  There is a reason for this.  When you write code in R, it is easy to fail to understand exactly what is happening “under the hood.” The structure of a maximum likelihood analysis is much more transparent when you are forced to build a spreadsheet. You may be delighted to know that this is the last time you will do this in this course.

Open the spreadsheet containing the light limitation data (**HemlockLightLikelihood.xlsx**).  In the next section you will add the proper formulas to columns and cells on the this sheet to demonstrate that you know how likelihood works.  Your spreadsheet will look something like this before answering questions 1 -- 9:

<br>

![ ](HemlockLightExampleImage1.png)

<br>

#### IV. Setting up the spreadsheet

Let’s think about the columns and the rows.  This is the benefit of this exercise, so please linger on this, discussing the layout of this spreadsheet with your classmates and calling on the instructors if you don’t understand it. 

* Columns A and B should be easy, these are the data. 

* Column C contains the prediction of your model for each level of light. These predictions depend on the values for $\alpha$, $\gamma$, and $c$ contained in column I.

* Column D contain the squared difference between observations and predictions.

* Column E contains the the probability density of the data conditional on $\mu_{i}$, and $\sigma$, one value for each data point. The Excel formula for this is `=NORMDIST(B2,C2,I$5,FALSE)`.

* Cells I2 -- I4 contain the values for $\alpha$, $\gamma$, and $c$ that are used to form the predicted growth rate as a function of light level (column C). Cell I5 contains the value for $\sigma$. Right now these cells are set to either 1 or 2. **You will replace these with better initial values before using the solver to find the maximum likelihood estimates (MLE) for each of these parameters.**

* Make a scatterplot of the data and the model predictions, where the x-axis is light level and the y-axis is growth increment. Plot the observed growth increments in blue and the predicted growth increments in green. For the moment, the predicted growth increments should form a line of points along the x-axis. 

<br>

Answer the following questions before proceeding.

1. How could you use the data to help you find good initial conditions for model parameters? 

<div class="hider">
Fitting model predictions by eye is a useful way to find reasonable intial values. You can get reasonable guesses for $c$ and $\alpha$ by simply looking at the plot of the data.
</div>

2. Adjust the values for $\alpha$, $\gamma$, and $c$ until you get predictions that look reasonable in your plot.  How could we get a better initial value for $\sigma$?

<div class="hider">
By calculating the $\sum_1^n\frac{1}{n}(y_i-\mu_i)^2$
</div>
3. Write the mathematics (the full equation) that is implemented in the formula in column E.
<div class="hider">

$$
L\big(\,\mu_{i},\sigma \mid y_{i}\,\big) = \cfrac{1}{\sigma\sqrt{2\pi}}e^{-\cfrac{\big(y_{i}-\mu_{i}\big)^{2}}{2\sigma^{2}}}\\[3em]
$$
</div>

<div class="hider">
4. Describe the correspondence between $y_{i}$, $\mu_{i}$, and $\sigma$ in equation 2 and the columns and cells in your spreadsheet.  
<div class="hider">
$y_{i}$ are the cells in column B, $\mu_{i}$ are the predictions of the model for each light level in colum C, and $\sigma$ is one of the parameters to be estimated in cell I5.
</div>


5. What is the reason for the argument “FALSE” in the Excel formula in column E?

<div class="hider">
It toggles the function from the CDF when the argument is "TRUE" to the PDF when it is false.
</div>
6. What does the function return when that argument is “TRUE”? 
<div class="hider">
See answer to 5.
</div>
7. In column F we take the logs of the likelihoods, which are summed in cell K2.  If we had not taken the logs and instead, worked directly with the likelihoods, what formula would we use in K2?
<div class="hider">

Product

</div>

<br>

8. What are some potential computational problems with using the individual likelihoods rather than the log likelihoods to estimate the total likelihood? 
<div class="hider">

Underflow

</div>

<br>

9. This model violates a fundamental assumption of traditional regression analysis.  What is that assumption?  How might you fix the problem? (Hint: think about what we are assuming about the covariate, light availability.)
<div class="hider">
The predictor variables are measured without error. We are interested in the light seen by the tree.  The x-values are an index to that unobserved qauntity.
</div>

<br>

#### V. Using Solver
Use Solver to find the maximum likelihood estimates of the parameters usig the spreadsheet you have constructed.  Solver is a sophisticated non-linear numerical optimizer that uses Newton's method to find values of parameters of a function that maximize or minimize the output of the function.  

If you have never used Solver, the main dialog box looks something like this:
    
<br>

<div style="width:400px; height=300px; margin:0 auto;">
![](HemlockLightExampleImage2.png)
</div>

<br>

Put the cell containing the sum of the log likelihoods in the **Set Objective** field.  The cells containing the parameter values will go into the **By Changing Variable Cells** field.  Most likely, you will be able to do the exercises without putting constraints on the parameter values if you give them reasonable starting values.  However, constraining parameters to reasonable values (e.g., $\alpha$ must be positive and can’t be too large) will prevent numerical errors and speed execution time.

10. How might you use the squared error column D to compute $\sigma$? Make this computation and compare with your maximum likelihood estimate of $\sigma$ obtained using Solver.

<br>

#### VI. Using R to do the same thing

Check your results using the ``nls`` function in R, which does non-linear estimation for normally distributed data. Examine the assumption that the model residuals are normally distributed using qqnorm.  To speed things along, I have given you the syntax, but for it to be useful to you, you must study it and experiment a bit.  In particular, you must do a help on ``nls`` and look at its methods—summary, predict, coef, and residuals.  The hemlock light and growth increment data are included in the course data library that you loaded the first week (ESS575).

```{r, eval = TRUE}
library(ESS575)
plot(HemlockLight$L, HemlockLight$g_rate, ylab = "Growth rate (cm/yr)", xlab = ("Light Availability"))

x = HemlockLight$L
y = HemlockLight$g_rate

model = nls(y ~ a * (x - c)/(a/s + x - c), trace = TRUE, start = c(a = 50, s = 2, c = 8))
summary(model)
p = (coef(model))
a.hat = p[1]
s.hat = p[2]
c.hat = p[3]
yhat = predict(model)

lines(x, yhat, col = "red")
```

<br>

#### VII. Incorporating prior information in an MLE 

Suppose that a previous study reported a mean value of $\alpha$ = 35 with a standard deviation of the mean =  4.25.You may use a normal distribution to represent the prior information on $\alpha$. Write  a model for the data that includes the prior information.

<div class="hider">
$L(\alpha, \gamma, c,\sigma| \mathbf{y}) =\prod_{i=1}^n\big(\text{normal}(g(\alpha,\gamma,c,L_i),\sigma^2)\big)\text{normal}(\alpha|35,4.25)$
</div>

Incorporate these prior data in your new MLE estimate of $\alpha$. Hint: create a likelihood function for the probability of the new value of $\alpha$ conditional on the previous value and its standard deviation. How do you combine likelihoods (or log likelihoods) to obtain a total likelihood?

11. Describe what happens to the estimate of α relative to the one you obtained earlier. What is going on? 

<div class="hider">
The estimate of $\alpha$  represents a compromise between the estimate based on the data and the prior distribution of $\alpha$.
</div>

12. What is the effect of increasing the prior standard deviation on the new estimate? What happens when it shrinks?

<div class="hider">
The effect of the prior distribution of $\alpha$ depends on its standard deviation.  Small values cause the current estimate of $\alpha$ to more closely resemble the prior mean.
</div>

13.  There is a single log likelihood for the prior distribution but the sum of many for the data. This seems "unfair."  Explain how the prior distribtion can overwhelm the data and vice versa.

<div class="hider">
The prior distribution might have been based on thousands of data points.  The prior distribution can overwhelm the data when it has a very small variance relative to the variance in the likelihood profile for $\alpha$.  The data can overwhelm the prior when the likelihood profile of $\alpha$ has a much lower variance than the variance of the prior. 
</div>
<br>

#### VIII. References

Coates, K.D., Burton P.J., 1999. Growth of planted tree seedlings in response to ambient light levels in northwestern interior cedar-hemlock forests of British Columbia. *Canadian Journal of Forest Research*, 1999, 29(9): 1374-1382, [10.1139/x99-091](http://northernforestatlas.com/research/pubs/burton_coates_1999_can_j_for_res.pdf)

